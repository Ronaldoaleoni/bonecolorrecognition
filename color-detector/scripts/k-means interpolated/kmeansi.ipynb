{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5a7d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enhanced_compute_bone_deltae2000.py\n",
    "\"\"\"\n",
    "Enhanced compute Î”E2000 for bone images against Munsell ground-truth using BIC-optimized k-means clustering.\n",
    "Designed for segmented bone images with black background.\n",
    "Incorporates improvements from the first pipeline including BIC optimization, better visualizations, and comprehensive analysis.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2016f1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, color\n",
    "from colour import xyY_to_XYZ\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from skimage.util import img_as_float\n",
    "from skimage.color import deltaE_ciede2000, lab2rgb\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.interpolate import RegularGridInterpolator  # Added for interpolation\n",
    "import colour  # Import colour-science library for CIEDE2000\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4052fc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Config\n",
    "BONE_IMAGES_DIR = r\"<your-path-here>\"\n",
    "MUNSELL_CSV = r\"<your-path-here>\\assets\\real_converted.csv\"\n",
    "OUTPUT_DIR = r\"<your-path-here>\"\n",
    "BACKGROUND_RGB_THRESH = 10  # threshold to exclude near-black background (0-255)\n",
    "MAX_K = 15  # Maximum clusters for BIC optimization\n",
    "TOP_N = 5  # Number of top matches to display (increased to 5)\n",
    "SUBSAMPLE_SIZE = 10000  # For BIC calculation efficiency\n",
    "USE_INTERPOLATION = True  # Enable interpolation for denser Munsell space\n",
    "INTERPOLATION_RESOLUTION = 5  # Controls interpolation density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8708f4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78682309",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_munsell_hue_notation(hue_value):\n",
    "    \"\"\"\n",
    "    Converts a H_GT value to a full Munsell hue notation.\n",
    "    Handles both numeric and string inputs.\n",
    "    \"\"\"\n",
    "    if pd.isna(hue_value):\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    # If it's already a string, return it as is\n",
    "    if isinstance(hue_value, str):\n",
    "        return hue_value\n",
    "    \n",
    "    # If it's numeric, use the mapping\n",
    "    try:\n",
    "        hue_number = float(hue_value)\n",
    "        hue_map = {\n",
    "            5: \"5R\", 7: \"7.5R\", 10: \"10R\", 12: \"2.5YR\", 15: \"5YR\",\n",
    "            17: \"7.5YR\", 20: \"10YR\", 22: \"2.5Y\", 25: \"5Y\", 30: \"10Y\", 35: \"5GY\"\n",
    "        }\n",
    "        return hue_map.get(int(hue_number), f\"{hue_number}H\")\n",
    "    except (ValueError, TypeError):\n",
    "        return \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6028f7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_full_munsell_notation(row):\n",
    "    \"\"\"Get full Munsell notation (H V/C) from a row.\"\"\"\n",
    "    # Try different possible column names for H, V, C\n",
    "    h = None\n",
    "    v = None\n",
    "    c = None\n",
    "    \n",
    "    # Check for various possible column names\n",
    "    for h_col in ['h', 'H_GT', 'H', 'h_gt', 'Hue']:\n",
    "        if h_col in row and not pd.isna(row[h_col]):\n",
    "            h = row[h_col]\n",
    "            break\n",
    "            \n",
    "    for v_col in ['V', 'V_GT', 'v_gt', 'v', 'Value']:\n",
    "        if v_col in row and not pd.isna(row[v_col]):\n",
    "            v = row[v_col]\n",
    "            break\n",
    "            \n",
    "    for c_col in ['C', 'C_GT', 'c_gt', 'c', 'Chroma']:\n",
    "        if c_col in row and not pd.isna(row[c_col]):\n",
    "            c = row[c_col]\n",
    "            break\n",
    "    \n",
    "    if h is None or v is None or c is None:\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    hue_notation = get_munsell_hue_notation(h)\n",
    "    return f\"{hue_notation} {v}/{c}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b2d707",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_interpolated_munsell_space(gt_df, resolution=INTERPOLATION_RESOLUTION):\n",
    "    \"\"\"Creates an interpolated Munsell color space from the ground truth data.\"\"\"\n",
    "    print(\"Creating interpolated Munsell color space...\")\n",
    "    \n",
    "    h_values = np.unique(gt_df['H_GT'].values)\n",
    "    v_values = np.unique(gt_df['V_GT'].values)\n",
    "    c_values = np.unique(gt_df['C_GT'].values)\n",
    "    \n",
    "    h_grid, v_grid, c_grid = np.meshgrid(h_values, v_values, c_values, indexing='ij')\n",
    "    \n",
    "    l_grid = np.full_like(h_grid, np.nan, dtype=float)\n",
    "    a_grid = np.full_like(h_grid, np.nan, dtype=float)\n",
    "    b_grid = np.full_like(h_grid, np.nan, dtype=float)\n",
    "    \n",
    "    for _, row in gt_df.iterrows():\n",
    "        h_idx = np.where(h_values == row['H_GT'])[0][0]\n",
    "        v_idx = np.where(v_values == row['V_GT'])[0][0]\n",
    "        c_idx = np.where(c_values == row['C_GT'])[0][0]\n",
    "        \n",
    "        l_grid[h_idx, v_idx, c_idx] = row['L_gt']\n",
    "        a_grid[h_idx, v_idx, c_idx] = row['a_gt']\n",
    "        b_grid[h_idx, v_idx, c_idx] = row['b_gt']\n",
    "    \n",
    "    l_interpolator = RegularGridInterpolator(\n",
    "        (h_values, v_values, c_values), \n",
    "        l_grid, \n",
    "        method='linear', \n",
    "        bounds_error=False, \n",
    "        fill_value=None\n",
    "    )\n",
    "    \n",
    "    a_interpolator = RegularGridInterpolator(\n",
    "        (h_values, v_values, c_values), \n",
    "        a_grid, \n",
    "        method='linear', \n",
    "        bounds_error=False, \n",
    "        fill_value=None\n",
    "    )\n",
    "    \n",
    "    b_interpolator = RegularGridInterpolator(\n",
    "        (h_values, v_values, c_values), \n",
    "        b_grid, \n",
    "        method='linear', \n",
    "        bounds_error=False, \n",
    "        fill_value=None\n",
    "    )\n",
    "    \n",
    "    h_fine = np.linspace(min(h_values), max(h_values), resolution * len(h_values))\n",
    "    v_fine = np.linspace(min(v_values), max(v_values), resolution * len(v_values))\n",
    "    c_fine = np.linspace(min(c_values), max(c_values), resolution * len(c_values))\n",
    "    \n",
    "    h_fine_grid, v_fine_grid, c_fine_grid = np.meshgrid(h_fine, v_fine, c_fine, indexing='ij')\n",
    "    \n",
    "    points = np.column_stack((h_fine_grid.ravel(), v_fine_grid.ravel(), c_fine_grid.ravel()))\n",
    "    \n",
    "    l_fine = l_interpolator(points).reshape(h_fine_grid.shape)\n",
    "    a_fine = a_interpolator(points).reshape(h_fine_grid.shape)\n",
    "    b_fine = b_interpolator(points).reshape(h_fine_grid.shape)\n",
    "    \n",
    "    interpolated_data = []\n",
    "    for i in range(len(h_fine)):\n",
    "        for j in range(len(v_fine)):\n",
    "            for k in range(len(c_fine)):\n",
    "                if not np.isnan(l_fine[i, j, k]):\n",
    "                    interpolated_data.append({\n",
    "                        'H_GT': h_fine[i],\n",
    "                        'V_GT': v_fine[j],\n",
    "                        'C_GT': c_fine[k],\n",
    "                        'L_gt': l_fine[i, j, k],\n",
    "                        'a_gt': a_fine[i, j, k],\n",
    "                        'b_gt': b_fine[i, j, k]\n",
    "                    })\n",
    "    \n",
    "    interpolated_df = pd.DataFrame(interpolated_data)\n",
    "    print(f\"Created interpolated Munsell space with {len(interpolated_df)} points\")\n",
    "    \n",
    "    # Add full Munsell notation to interpolated data\n",
    "    interpolated_df['munsell_notation'] = interpolated_df.apply(get_full_munsell_notation, axis=1)\n",
    "    \n",
    "    # Add RGB values for display\n",
    "    lab_values = interpolated_df[['L_gt', 'a_gt', 'b_gt']].values\n",
    "    rgb_values = lab2rgb(lab_values.reshape(-1, 1, 3)).reshape(-1, 3)\n",
    "    interpolated_df[['R_display', 'G_display', 'B_display']] = rgb_values\n",
    "    \n",
    "    return interpolated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a465cf",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def calculate_bic(bone_pixels_lab, max_k=MAX_K, subsample_size=SUBSAMPLE_SIZE, output_dir=None, image_name=None):\n",
    "    \"\"\"\n",
    "    Calculates BIC for K-Means clustering and plots an elbow plot.\n",
    "    \"\"\"\n",
    "    n = len(bone_pixels_lab)\n",
    "    d = 3  # CIELAB dimensions\n",
    "\n",
    "    if n > subsample_size:\n",
    "        indices = np.random.choice(n, subsample_size, replace=False)\n",
    "        bone_pixels_sample = bone_pixels_lab[indices]\n",
    "    else:\n",
    "        bone_pixels_sample = bone_pixels_lab\n",
    "\n",
    "    bic_values = []\n",
    "    for k in range(1, max_k + 1):\n",
    "        if k == 1:\n",
    "            mean_pixel = np.mean(bone_pixels_sample, axis=0)\n",
    "            wcss = np.sum((bone_pixels_sample - mean_pixel) ** 2)\n",
    "        else:\n",
    "            kmeans_temp = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "            kmeans_temp.fit(bone_pixels_sample)\n",
    "            wcss = kmeans_temp.inertia_\n",
    "        bic = n * np.log(wcss / n) + k * d * np.log(n) if wcss > 0 else float('inf')\n",
    "        bic_values.append(bic)\n",
    "\n",
    "    optimal_k = np.argmin(bic_values) + 1\n",
    "    print(f\"Optimal number of clusters determined by BIC: {optimal_k}\")\n",
    "\n",
    "    # Generate elbow plot\n",
    "    if output_dir and image_name:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(range(1, max_k + 1), bic_values, marker='o')\n",
    "        plt.xlabel('Number of Clusters (K)')\n",
    "        plt.ylabel('BIC')\n",
    "        #plt.title('BIC Elbow Plot')\n",
    "        plt.grid(True)\n",
    "        elbow_plot_path = os.path.join(output_dir, f\"{image_name}_bic_elbow_plot.png\")\n",
    "        plt.savefig(elbow_plot_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Elbow plot saved to: {elbow_plot_path}\")\n",
    "\n",
    "    return optimal_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0658b0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_munsell_groundtruth(csv_path, use_interpolation=USE_INTERPOLATION):\n",
    "    \"\"\"Enhanced ground-truth loading with interpolation option.\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Normalize column names for case-insensitive matching\n",
    "    col_lower = {c.lower(): c for c in df.columns}\n",
    "    \n",
    "    # Check for different column naming conventions\n",
    "    has_xyY = ('x' in col_lower and 'y' in col_lower and 'y' in col_lower)\n",
    "    has_rgb = ('r' in col_lower and 'g' in col_lower and 'b' in col_lower)\n",
    "    has_lab = ('l' in col_lower and 'a' in col_lower and 'b' in col_lower)\n",
    "\n",
    "    if has_xyY and 'y' in col_lower:\n",
    "        # xyY conversion\n",
    "        x = df['x'].values.astype(float)\n",
    "        y = df['y'].values.astype(float)\n",
    "        Y = df['Y'].values.astype(float)\n",
    "        \n",
    "        xyz = np.array([xyY_to_XYZ((xx, yy, yy_val)) for xx, yy, yy_val in zip(x,y,Y)])\n",
    "        lab = color.xyz2lab(xyz / 100.0)\n",
    "        df[['L_gt','a_gt','b_gt']] = lab\n",
    "        \n",
    "    elif has_rgb:\n",
    "        # RGB conversion\n",
    "        rgb_cols = [col_lower['r'], col_lower['g'], col_lower['b']]\n",
    "        rgb = df[rgb_cols].values.astype(float) / 255.0\n",
    "        lab = color.rgb2lab(rgb.reshape(-1,1,3)).reshape(-1,3)\n",
    "        df[['L_gt','a_gt','b_gt']] = lab\n",
    "        \n",
    "    elif has_lab:\n",
    "        # Direct Lab values\n",
    "        lab_cols = [col_lower['l'], col_lower['a'], col_lower['b']]\n",
    "        df['L_gt'] = df[lab_cols[0]]\n",
    "        df['a_gt'] = df[lab_cols[1]]\n",
    "        df['b_gt'] = df[lab_cols[2]]\n",
    "    else:\n",
    "        raise ValueError(f\"Ground-truth CSV doesn't contain recognizable color columns. Found: {list(df.columns)}\")\n",
    "\n",
    "    # Add full Munsell notation\n",
    "    df['munsell_notation'] = df.apply(get_full_munsell_notation, axis=1)\n",
    "    \n",
    "    # Add RGB values for display\n",
    "    lab_values = df[['L_gt', 'a_gt', 'b_gt']].values\n",
    "    rgb_values = lab2rgb(lab_values.reshape(-1, 1, 3)).reshape(-1, 3)\n",
    "    df[['R_display', 'G_display', 'B_display']] = rgb_values\n",
    "    \n",
    "    # Apply interpolation if requested and possible\n",
    "    if use_interpolation and 'H_GT' in df.columns and 'V_GT' in df.columns and 'C_GT' in df.columns:\n",
    "        return create_interpolated_munsell_space(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f01542",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extract_bone_pixels(img_path, bg_thresh=BACKGROUND_RGB_THRESH):\n",
    "    \"\"\"Enhanced bone pixel extraction with better handling.\"\"\"\n",
    "    img = io.imread(img_path)\n",
    "    if img.ndim == 2:\n",
    "        img = np.stack([img]*3, axis=-1)\n",
    "    \n",
    "    # Create mask for non-background pixels\n",
    "    mask = np.sum(img, axis=2) > bg_thresh * 3\n",
    "    bone_pixels_rgb = img[mask]\n",
    "    \n",
    "    if bone_pixels_rgb.size == 0:\n",
    "        return None, None\n",
    "    \n",
    "    # Convert to Lab color space using the same method as pipeline 1\n",
    "    bone_pixels_rgb_float = bone_pixels_rgb.astype(np.float32) / 255.0\n",
    "    bone_pixels_rgb_float_reshaped = bone_pixels_rgb_float.reshape(-1, 1, 3)\n",
    "    \n",
    "    # Use cv2-style conversion for consistency\n",
    "    import cv2\n",
    "    bone_lab = cv2.cvtColor(bone_pixels_rgb_float_reshaped, cv2.COLOR_RGB2Lab)\n",
    "    bone_lab = bone_lab.reshape(-1, 3)\n",
    "    \n",
    "    return bone_lab, bone_pixels_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5172af0e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def cluster_bone_pixels_optimized(bone_lab, img_name, output_dir):\n",
    "    \"\"\"Enhanced clustering with BIC optimization.\"\"\"\n",
    "    # Determine optimal number of clusters\n",
    "    optimal_k = calculate_bic(bone_lab, MAX_K, output_dir=output_dir, image_name=img_name)\n",
    "    \n",
    "    # Apply k-means clustering\n",
    "    kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(bone_lab)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    \n",
    "    # Calculate cluster sizes\n",
    "    cluster_sizes = np.bincount(labels)\n",
    "    \n",
    "    return centers, cluster_sizes, labels, optimal_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3544332",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def find_top_matches_enhanced(cluster_center, gt_df, top_n=TOP_N):\n",
    "    \"\"\"Enhanced matching using CIEDE2000 from colour library.\"\"\"\n",
    "    gt_lab_arr = gt_df[['L_gt','a_gt','b_gt']].values.astype(float)\n",
    "    \n",
    "    # Use colour library for CIEDE2000 (more accurate)\n",
    "    dE = colour.delta_E(cluster_center[np.newaxis, :], gt_lab_arr, method='CIE 2000')\n",
    "    \n",
    "    # Get indices of top N matches (lowest dE)\n",
    "    top_indices = np.argsort(dE)[:top_n]\n",
    "    \n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        row = gt_df.iloc[idx]\n",
    "        rgb_values = (row.get('R_display', 0), row.get('G_display', 0), row.get('B_display', 0))\n",
    "        \n",
    "        # Extract H, V, C values using various possible column names\n",
    "        h_val = None\n",
    "        v_val = None\n",
    "        c_val = None\n",
    "        \n",
    "        for h_col in ['h', 'H_GT', 'H', 'h_gt', 'Hue']:\n",
    "            if h_col in row and not pd.isna(row[h_col]):\n",
    "                h_val = row[h_col]\n",
    "                break\n",
    "                \n",
    "        for v_col in ['V', 'V_GT', 'v_gt', 'v', 'Value']:\n",
    "            if v_col in row and not pd.isna(row[v_col]):\n",
    "                v_val = row[v_col]\n",
    "                break\n",
    "                \n",
    "        for c_col in ['C', 'C_GT', 'c_gt', 'c', 'Chroma']:\n",
    "            if c_col in row and not pd.isna(row[c_col]):\n",
    "                c_val = row[c_col]\n",
    "                break\n",
    "        \n",
    "        results.append({\n",
    "            'dE': dE[idx],\n",
    "            'H': h_val,\n",
    "            'V': v_val,\n",
    "            'C': c_val,\n",
    "            'L_gt': row['L_gt'],\n",
    "            'a_gt': row['a_gt'],\n",
    "            'b_gt': row['b_gt'],\n",
    "            'munsell_notation': row.get('munsell_notation', 'Unknown'),\n",
    "            'rgb_values': rgb_values\n",
    "        })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c521a982",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_3d_scatter_best_cluster(bone_pixels_cluster, munsell_chip_lab, output_path):\n",
    "    \"\"\"Enhanced 3D scatter plot for the best cluster with perceptual coloring.\"\"\"\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Subsample for visualization if too many points\n",
    "    if len(bone_pixels_cluster) > 5000:\n",
    "        indices = np.random.choice(len(bone_pixels_cluster), 5000, replace=False)\n",
    "        plot_pixels = bone_pixels_cluster[indices]\n",
    "    else:\n",
    "        plot_pixels = bone_pixels_cluster\n",
    "    \n",
    "    # Calculate distance from each point to the Munsell chip\n",
    "    distances = np.sqrt(np.sum((plot_pixels - munsell_chip_lab)**2, axis=1))\n",
    "    \n",
    "    # Normalize distances for colormap\n",
    "    norm = plt.Normalize(vmin=distances.min(), vmax=distances.max())\n",
    "    cmap = plt.cm.viridis  # Perceptually uniform sequential colormap\n",
    "    \n",
    "    # Plot points with color based on distance\n",
    "    scatter = ax.scatter(plot_pixels[:, 0], plot_pixels[:, 1], plot_pixels[:, 2], \n",
    "                         c=distances, cmap=cmap, norm=norm, alpha=0.4, s=10)\n",
    "    \n",
    "    # Plot the Munsell chip\n",
    "    ax.scatter(munsell_chip_lab[0], munsell_chip_lab[1], munsell_chip_lab[2], \n",
    "               c='red', marker='o', s=300, label='Munsell Chip', edgecolors='black')\n",
    "    \n",
    "    ax.set_xlabel('L*')\n",
    "    ax.set_ylabel('a*')\n",
    "    ax.set_zlabel('b*')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(scatter, ax=ax, shrink=0.5, aspect=20)\n",
    "    cbar.set_label('Distance from Munsell Chip (Î”E)')\n",
    "    \n",
    "    #plt.title('Best Cluster Pixels and Munsell Chip in CIELAB Space\\n(Colored by Distance)')\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03fa9b0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_enhanced_visualization(img_path, cluster_centers, cluster_sizes, top_matches_list, \n",
    "                                optimal_k, bone_lab, cluster_labels, gt_df, output_dir, img_name):\n",
    "    \"\"\"Enhanced visualization combining both pipelines' strengths.\"\"\"\n",
    "    \n",
    "    # 1. Main comparison plot (showing top 5 clusters)\n",
    "    top_indices = np.argsort([matches[0]['dE'] for matches in top_matches_list])[:min(5, optimal_k)]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(top_indices) + 1, figsize=(22, 5))\n",
    "    \n",
    "    # Original image\n",
    "    img = io.imread(img_path)\n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_title(f\"Bone Image\\n(K={optimal_k} clusters)\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Top matches visualization\n",
    "    for i, cluster_idx in enumerate(top_indices):\n",
    "        match = top_matches_list[cluster_idx][0]  # Best match for this cluster\n",
    "        \n",
    "        # Get RGB color for display\n",
    "        rgb_color = match['rgb_values']\n",
    "        \n",
    "        axes[i + 1].imshow([[rgb_color]])\n",
    "        \n",
    "        munsell_notation = match['munsell_notation']\n",
    "        rgb_text = f\"RGB: ({rgb_color[0]:.2f}, {rgb_color[1]:.2f}, {rgb_color[2]:.2f})\"\n",
    "        \n",
    "        axes[i + 1].set_title(f\"Cluster {cluster_idx + 1} Match\\n{munsell_notation}\\n{rgb_text}\\nÎ”E2000: {match['dE']:.2f}\\nSize: {cluster_sizes[cluster_idx]} px\")\n",
    "        axes[i + 1].axis('off')\n",
    "        axes[i + 1].add_patch(Rectangle((0, 0), 1, 1, facecolor=rgb_color, edgecolor='black', linewidth=2))\n",
    "\n",
    "    #plt.suptitle(f\"Enhanced Color Analysis: {os.path.basename(img_path)}\", fontsize=14)\n",
    "    main_plot_path = os.path.join(output_dir, f\"{img_name}_enhanced_analysis.png\")\n",
    "    plt.savefig(main_plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. 3D scatter plot for best cluster\n",
    "    best_cluster_idx = np.argmin([matches[0]['dE'] for matches in top_matches_list])\n",
    "    best_cluster_pixels = bone_lab[cluster_labels == best_cluster_idx]\n",
    "    best_match = top_matches_list[best_cluster_idx][0]\n",
    "    best_munsell_lab = np.array([best_match['L_gt'], best_match['a_gt'], best_match['b_gt']])\n",
    "    \n",
    "    scatter_path = os.path.join(output_dir, f\"{img_name}_3d_scatter.png\")\n",
    "    plot_3d_scatter_best_cluster(best_cluster_pixels, best_munsell_lab, scatter_path)\n",
    "    \n",
    "    # 3. Detailed analysis plot (from pipeline 2)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0, 0].imshow(img)\n",
    "    axes[0, 0].set_title('Original Bone Image')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Cluster centers in Lab space\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, optimal_k))\n",
    "    for i, (center, size) in enumerate(zip(cluster_centers, cluster_sizes)):\n",
    "        rgb_color = lab2rgb(center.reshape(1, 1, 3)).reshape(3)\n",
    "        rgb_color = np.clip(rgb_color, 0, 1)\n",
    "        axes[0, 1].scatter(center[1], center[2], color=rgb_color, s=size/10, \n",
    "                          alpha=0.7, edgecolor='black', label=f'Cluster {i+1}')\n",
    "    \n",
    "    axes[0, 1].set_xlabel('a*')\n",
    "    axes[0, 1].set_ylabel('b*')\n",
    "    axes[0, 1].set_title('Cluster Centers in Lab Space (size = pixel count/10)')\n",
    "    axes[0, 1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Î”E distribution by cluster\n",
    "    for cluster_idx, (top_matches, color) in enumerate(zip(top_matches_list, colors)):\n",
    "        dE_values = [match['dE'] for match in top_matches]\n",
    "        axes[1, 0].plot(range(1, min(len(dE_values), TOP_N)+1), dE_values[:TOP_N], \n",
    "                       'o-', color=color, label=f'Cluster {cluster_idx+1}')\n",
    "    \n",
    "    axes[1, 0].set_xlabel('Match Rank')\n",
    "    axes[1, 0].set_ylabel('Î”E2000')\n",
    "    axes[1, 0].set_title('Î”E2000 for Top Matches by Cluster')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Color swatches for best cluster (top 5 matches)\n",
    "    best_matches = top_matches_list[best_cluster_idx][:5]\n",
    "    for i, match in enumerate(best_matches):\n",
    "        rgb_color = match['rgb_values']\n",
    "        axes[1, 1].add_patch(plt.Rectangle((i, 0), 0.8, 0.8, color=rgb_color, edgecolor='black'))\n",
    "        axes[1, 1].text(i + 0.4, -0.15, f\"Î”E={match['dE']:.2f}\", ha='center', fontsize=10)\n",
    "        munsell_text = match['munsell_notation']\n",
    "        axes[1, 1].text(i + 0.4, 0.9, munsell_text, ha='center', fontsize=9, rotation=45)\n",
    "    \n",
    "    axes[1, 1].set_xlim(-0.5, 5.5)\n",
    "    axes[1, 1].set_ylim(-0.5, 1.2)\n",
    "    axes[1, 1].set_title(f'Top 5 Matches for Best Cluster ({best_cluster_idx + 1})')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    detailed_path = os.path.join(output_dir, f\"{img_name}_detailed_analysis.png\")\n",
    "    plt.savefig(detailed_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Dendrogram\n",
    "    if optimal_k > 1:\n",
    "        cluster_best_dE = [matches[0]['dE'] for matches in top_matches_list]\n",
    "        cluster_labels_dend = [\n",
    "            f\"C{i+1}: {top_matches_list[i][0]['munsell_notation']} (Î”E={top_matches_list[i][0]['dE']:.2f})\"\n",
    "            for i in range(optimal_k)\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            linked = linkage(np.array(cluster_best_dE).reshape(-1, 1), 'ward')\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            dendrogram(linked, orientation='top', labels=cluster_labels_dend, \n",
    "                      distance_sort='ascending', leaf_font_size=10)\n",
    "            plt.title(f\"Cluster Similarity Dendrogram: {os.path.basename(img_path)}\")\n",
    "            plt.xlabel(\"Clusters with Best Munsell Matches\")\n",
    "            plt.ylabel(\"Linkage Distance\")\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.tight_layout()\n",
    "            dendro_path = os.path.join(output_dir, f\"{img_name}_dendrogram.png\")\n",
    "            plt.savefig(dendro_path, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Could not create dendrogram: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c766f0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def process_single_image(img_path, gt_df, output_dir):\n",
    "    \"\"\"Process a single bone image with enhanced pipeline.\"\"\"\n",
    "    img_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    \n",
    "    try:\n",
    "        # Extract bone pixels\n",
    "        bone_lab, bone_rgb = extract_bone_pixels(img_path)\n",
    "        if bone_lab is None:\n",
    "            print(f\"Skipping {img_path} - no bone pixels detected\")\n",
    "            return []\n",
    "        \n",
    "        print(f\"  Found {len(bone_lab)} bone pixels\")\n",
    "        \n",
    "        # Apply optimized clustering\n",
    "        cluster_centers, cluster_sizes, cluster_labels, optimal_k = cluster_bone_pixels_optimized(\n",
    "            bone_lab, img_name, output_dir)\n",
    "        \n",
    "        print(f\"  Clustered into {optimal_k} groups\")\n",
    "        \n",
    "        # Find top matches for each cluster\n",
    "        top_matches_list = []\n",
    "        cluster_results = []\n",
    "        \n",
    "        for i, center in enumerate(cluster_centers):\n",
    "            top_matches = find_top_matches_enhanced(center, gt_df, top_n=TOP_N)\n",
    "            top_matches_list.append(top_matches)\n",
    "            \n",
    "            # Store results\n",
    "            for j, match in enumerate(top_matches):\n",
    "                cluster_results.append({\n",
    "                    \"image_path\": img_path,\n",
    "                    \"image_name\": img_name,\n",
    "                    \"cluster_id\": i+1,\n",
    "                    \"cluster_size\": cluster_sizes[i],\n",
    "                    \"cluster_size_pct\": cluster_sizes[i] / len(bone_lab) * 100,\n",
    "                    \"optimal_k\": optimal_k,\n",
    "                    \"cluster_L\": center[0],\n",
    "                    \"cluster_a\": center[1],\n",
    "                    \"cluster_b\": center[2],\n",
    "                    \"match_rank\": j+1,\n",
    "                    \"dE2000\": match['dE'],\n",
    "                    \"gt_H\": match['H'],\n",
    "                    \"gt_V\": match['V'],\n",
    "                    \"gt_C\": match['C'],\n",
    "                    \"gt_L\": match['L_gt'],\n",
    "                    \"gt_a\": match['a_gt'],\n",
    "                    \"gt_b\": match['b_gt'],\n",
    "                    \"munsell_notation\": match['munsell_notation'],\n",
    "                    \"rgb_R\": match['rgb_values'][0],\n",
    "                    \"rgb_G\": match['rgb_values'][1],\n",
    "                    \"rgb_B\": match['rgb_values'][2],\n",
    "                    \"interpolation_used\": USE_INTERPOLATION  # Added: Record interpolation status\n",
    "                })\n",
    "        \n",
    "        # Create enhanced visualizations\n",
    "        create_enhanced_visualization(img_path, cluster_centers, cluster_sizes, top_matches_list,\n",
    "                                    optimal_k, bone_lab, cluster_labels, gt_df, output_dir, img_name)\n",
    "        \n",
    "        print(f\"  Generated visualizations and analysis\")\n",
    "        return cluster_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_path}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ea147a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ========== MAIN EXECUTION ==========\n",
    "def main():\n",
    "    print(\"Enhanced Bone Color Analysis Pipeline\")\n",
    "    print(\"=====================================\")\n",
    "    print(f\"Using interpolated Munsell space: {USE_INTERPOLATION}\")\n",
    "    if USE_INTERPOLATION:\n",
    "        print(f\"Interpolation resolution: {INTERPOLATION_RESOLUTION}\")\n",
    "    \n",
    "    # Load ground truth\n",
    "    print(\"Loading Munsell ground truth...\")\n",
    "    try:\n",
    "        gt_df = load_munsell_groundtruth(MUNSELL_CSV, USE_INTERPOLATION)\n",
    "        print(f\"Loaded {len(gt_df)} Munsell color references\")\n",
    "        \n",
    "        # Print column names to help debug\n",
    "        print(f\"Columns in ground truth: {list(gt_df.columns)}\")\n",
    "        \n",
    "        # Check if Munsell notation is working\n",
    "        print(f\"Sample Munsell notations: {gt_df['munsell_notation'].head()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading ground truth: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Get image files\n",
    "    image_paths = []\n",
    "    for fname in os.listdir(BONE_IMAGES_DIR):\n",
    "        if fname.lower().endswith(('.png','.jpg','.jpeg','.tiff','.bmp')):\n",
    "            image_paths.append(os.path.join(BONE_IMAGES_DIR, fname))\n",
    "    \n",
    "    if not image_paths:\n",
    "        print(f\"No images found in {BONE_IMAGES_DIR}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(image_paths)} bone images to process\")\n",
    "    \n",
    "    # Process all images\n",
    "    all_results = []\n",
    "    for img_path in tqdm(image_paths, desc=\"Processing images\"):\n",
    "        print(f\"\\nProcessing: {os.path.basename(img_path)}\")\n",
    "        results = process_single_image(img_path, gt_df, OUTPUT_DIR)\n",
    "        all_results.extend(results)\n",
    "    \n",
    "    # Save comprehensive results\n",
    "    if all_results:\n",
    "        print(f\"\\nSaving results for {len(all_results)} cluster matches...\")\n",
    "        \n",
    "        res_df = pd.DataFrame(all_results)\n",
    "        all_csv = os.path.join(OUTPUT_DIR, \"enhanced_bone_deltae_results.csv\")\n",
    "        res_df.to_csv(all_csv, index=False)\n",
    "        print(f\"Detailed results: {all_csv}\")\n",
    "        \n",
    "        # Enhanced summary statistics\n",
    "        summary_stats = res_df.groupby(['image_name', 'optimal_k']).agg({\n",
    "            'dE2000': ['min', 'mean', 'max', 'std'],\n",
    "            'cluster_id': 'count',\n",
    "            'cluster_size': 'sum'\n",
    "        }).round(3)\n",
    "        \n",
    "        summary_stats.columns = ['min_dE', 'mean_dE', 'max_dE', 'std_dE', 'total_matches', 'total_pixels']\n",
    "        summary_csv = os.path.join(OUTPUT_DIR, \"enhanced_summary_statistics.csv\")\n",
    "        summary_stats.to_csv(summary_csv)\n",
    "        print(f\"Summary statistics: {summary_csv}\")\n",
    "        \n",
    "        # Overall analysis plots\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Î”E distribution\n",
    "        axes[0,0].hist(res_df['dE2000'], bins=50, alpha=0.7, edgecolor='black')\n",
    "        axes[0,0].set_xlabel('Î”E2000')\n",
    "        axes[0,0].set_ylabel('Frequency')\n",
    "        axes[0,0].set_title('Distribution of Î”E2000 Values')\n",
    "        axes[0,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Optimal K distribution\n",
    "        k_counts = res_df.groupby('image_name')['optimal_k'].first().value_counts().sort_index()\n",
    "        axes[0,1].bar(k_counts.index, k_counts.values)\n",
    "        axes[0,1].set_xlabel('Optimal K (BIC)')\n",
    "        axes[0,1].set_ylabel('Number of Images')\n",
    "        axes[0,1].set_title('Distribution of Optimal Cluster Numbers')\n",
    "        axes[0,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Best matches by rank\n",
    "        rank_stats = res_df.groupby('match_rank')['dE2000'].mean()\n",
    "        axes[1,0].plot(rank_stats.index, rank_stats.values, 'o-')\n",
    "        axes[1,0].set_xlabel('Match Rank')\n",
    "        axes[1,0].set_ylabel('Average Î”E2000')\n",
    "        axes[1,0].set_title('Average Î”E2000 by Match Rank')\n",
    "        axes[1,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Cluster size vs Î”E\n",
    "        best_matches = res_df[res_df['match_rank'] == 1]\n",
    "        axes[1,1].scatter(best_matches['cluster_size_pct'], best_matches['dE2000'], alpha=0.6)\n",
    "        axes[1,1].set_xlabel('Cluster Size (%)')\n",
    "        axes[1,1].set_ylabel('Best Match Î”E2000')\n",
    "        axes[1,1].set_title('Cluster Size vs Color Accuracy')\n",
    "        axes[1,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        overall_path = os.path.join(OUTPUT_DIR, \"overall_analysis.png\")\n",
    "        plt.savefig(overall_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Overall analysis: {overall_path}\")\n",
    "        \n",
    "        # Print comprehensive summary\n",
    "        print(f\"\\n=== ANALYSIS COMPLETE ===\")\n",
    "        print(f\"Processed: {len(image_paths)} images\")\n",
    "        print(f\"Generated: {len(all_results)} cluster-match pairs\")\n",
    "        print(f\"Best Î”E2000: {res_df['dE2000'].min():.2f}\")\n",
    "        print(f\"Worst Î”E2000: {res_df['dE2000'].max():.2f}\")\n",
    "        print(f\"Mean Î”E2000: {res_df['dE2000'].mean():.2f}\")\n",
    "        print(f\"Median Î”E2000: {res_df['dE2000'].median():.2f}\")\n",
    "        print(f\"Standard Deviation: {res_df['dE2000'].std():.2f}\")\n",
    "        print(f\"Interpolation used: {USE_INTERPOLATION}\")\n",
    "        print(f\"Results saved to: {OUTPUT_DIR}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"No results generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b320bab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40e2bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Enhanced compute Î”E2000 for bone images against Munsell ground-truth using median cut color quantization.\n",
    "Designed for segmented bone images with black background.\n",
    "Includes comprehensive statistics calculation (min, max, mean, std).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2baa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, color\n",
    "from colour import xyY_to_XYZ\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from skimage.util import img_as_float\n",
    "from skimage.color import deltaE_ciede2000, lab2rgb\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import colour  \n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5208e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Config\n",
    "BONE_IMAGES_DIR = r\"<your-path-here>\"\n",
    "MUNSELL_CSV = r\"<your-path-here>\\assets\\real_converted.csv\"\n",
    "OUTPUT_DIR = r\"<your-path-here>\"\n",
    "BACKGROUND_RGB_THRESH = 10  # threshold to exclude near-black background (0-255)\n",
    "QUANTIZATION_LEVELS = 32  # Number of colors for median cut quantization (power of 2 works best)\n",
    "TOP_N = 5  # Number of top matches to display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb09a9d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba8cf8f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_munsell_hue_notation(hue_value):\n",
    "    \"\"\"\n",
    "    Converts a H_GT value to a full Munsell hue notation.\n",
    "    Handles both numeric and string inputs.\n",
    "    \"\"\"\n",
    "    if pd.isna(hue_value):\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    # If it's already a string, return it as is\n",
    "    if isinstance(hue_value, str):\n",
    "        return hue_value\n",
    "    \n",
    "    # If it's numeric, use the mapping\n",
    "    try:\n",
    "        hue_number = float(hue_value)\n",
    "        hue_map = {\n",
    "            5: \"5R\", 7: \"7.5R\", 10: \"10R\", 12: \"2.5YR\", 15: \"5YR\",\n",
    "            17: \"7.5YR\", 20: \"10YR\", 22: \"2.5Y\", 25: \"5Y\", 30: \"10Y\", 35: \"5GY\"\n",
    "        }\n",
    "        return hue_map.get(int(hue_number), f\"{hue_number}H\")\n",
    "    except (ValueError, TypeError):\n",
    "        return \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c90729c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_full_munsell_notation(row):\n",
    "    \"\"\"Get full Munsell notation (H V/C) from a row.\"\"\"\n",
    "    # Try different possible column names for H, V, C\n",
    "    h = None\n",
    "    v = None\n",
    "    c = None\n",
    "    \n",
    "    # Check for various possible column names\n",
    "    for h_col in ['h', 'H_GT', 'H', 'h_gt', 'Hue']:\n",
    "        if h_col in row and not pd.isna(row[h_col]):\n",
    "            h = row[h_col]\n",
    "            break\n",
    "            \n",
    "    for v_col in ['V', 'V_GT', 'v_gt', 'v', 'Value']:\n",
    "        if v_col in row and not pd.isna(row[v_col]):\n",
    "            v = row[v_col]\n",
    "            break\n",
    "            \n",
    "    for c_col in ['C', 'C_GT', 'c_gt', 'c', 'Chroma']:\n",
    "        if c_col in row and not pd.isna(row[c_col]):\n",
    "            c = row[c_col]\n",
    "            break\n",
    "    \n",
    "    if h is None or v is None or c is None:\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    hue_notation = get_munsell_hue_notation(h)\n",
    "    return f\"{hue_notation} {v}/{c}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7085745a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def median_cut_quantization(rgb_pixels, num_colors):\n",
    "    \"\"\"\n",
    "    Implement median cut algorithm for color quantization.\n",
    "    \n",
    "    Args:\n",
    "        rgb_pixels: Array of RGB pixels (N, 3)\n",
    "        num_colors: Number of colors to quantize to (should be power of 2)\n",
    "    \n",
    "    Returns:\n",
    "        quantized_colors: Array of quantized colors (num_colors, 3)\n",
    "        labels: Cluster labels for each pixel (N,)\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying original data\n",
    "    pixels = rgb_pixels.copy()\n",
    "    \n",
    "    # Initialize with all pixels in one bucket\n",
    "    buckets = [pixels]\n",
    "    \n",
    "    # Split buckets until we reach the desired number of colors\n",
    "    while len(buckets) < num_colors:\n",
    "        new_buckets = []\n",
    "        \n",
    "        for bucket in buckets:\n",
    "            if len(bucket) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Find the color channel with the greatest range\n",
    "            r_range = np.max(bucket[:, 0]) - np.min(bucket[:, 0])\n",
    "            g_range = np.max(bucket[:, 1]) - np.min(bucket[:, 1])\n",
    "            b_range = np.max(bucket[:, 2]) - np.min(bucket[:, 2])\n",
    "            \n",
    "            # Determine which channel to split along\n",
    "            if r_range >= g_range and r_range >= b_range:\n",
    "                channel = 0  # Red\n",
    "            elif g_range >= r_range and g_range >= b_range:\n",
    "                channel = 1  # Green\n",
    "            else:\n",
    "                channel = 2  # Blue\n",
    "            \n",
    "            # Sort the bucket along the selected channel\n",
    "            sorted_bucket = bucket[bucket[:, channel].argsort()]\n",
    "            \n",
    "            # Find the median and split\n",
    "            median_idx = len(sorted_bucket) // 2\n",
    "            new_buckets.append(sorted_bucket[:median_idx])\n",
    "            new_buckets.append(sorted_bucket[median_idx:])\n",
    "        \n",
    "        buckets = new_buckets\n",
    "        \n",
    "        # If we've reached the desired number of buckets, break\n",
    "        if len(buckets) >= num_colors:\n",
    "            break\n",
    "    \n",
    "    # Calculate the average color for each bucket\n",
    "    quantized_colors = []\n",
    "    for bucket in buckets:\n",
    "        if len(bucket) > 0:\n",
    "            avg_color = np.mean(bucket, axis=0)\n",
    "            quantized_colors.append(avg_color)\n",
    "    \n",
    "    # If we have fewer colors than requested, duplicate the last color\n",
    "    while len(quantized_colors) < num_colors:\n",
    "        quantized_colors.append(quantized_colors[-1])\n",
    "    \n",
    "    quantized_colors = np.array(quantized_colors)\n",
    "    \n",
    "    # Assign each pixel to the closest quantized color\n",
    "    labels = np.zeros(len(pixels), dtype=int)\n",
    "    for i, pixel in enumerate(pixels):\n",
    "        distances = np.sqrt(np.sum((quantized_colors - pixel) ** 2, axis=1))\n",
    "        labels[i] = np.argmin(distances)\n",
    "    \n",
    "    return quantized_colors, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b2b19a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_munsell_groundtruth(csv_path):\n",
    "    \"\"\"Enhanced ground-truth loading with better error handling and column detection.\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Normalize column names for case-insensitive matching\n",
    "    col_lower = {c.lower(): c for c in df.columns}\n",
    "    \n",
    "    # Check for different column naming conventions\n",
    "    has_xyY = ('x' in col_lower and 'y' in col_lower and 'y' in col_lower)\n",
    "    has_rgb = ('r' in col_lower and 'g' in col_lower and 'b' in col_lower)\n",
    "    has_lab = ('l' in col_lower and 'a' in col_lower and 'b' in col_lower)\n",
    "\n",
    "    if has_xyY and 'y' in col_lower:\n",
    "        # xyY conversion\n",
    "        x = df['x'].values.astype(float)\n",
    "        y = df['y'].values.astype(float)\n",
    "        Y = df['Y'].values.astype(float)\n",
    "        \n",
    "        xyz = np.array([xyY_to_XYZ((xx, yy, yy_val)) for xx, yy, yy_val in zip(x,y,Y)])\n",
    "        lab = color.xyz2lab(xyz / 100.0)\n",
    "        df[['L_gt','a_gt','b_gt']] = lab\n",
    "        \n",
    "    elif has_rgb:\n",
    "        # RGB conversion\n",
    "        rgb_cols = [col_lower['r'], col_lower['g'], col_lower['b']]\n",
    "        rgb = df[rgb_cols].values.astype(float) / 255.0\n",
    "        lab = color.rgb2lab(rgb.reshape(-1,1,3)).reshape(-1,3)\n",
    "        df[['L_gt','a_gt','b_gt']] = lab\n",
    "        \n",
    "    elif has_lab:\n",
    "        # Direct Lab values\n",
    "        lab_cols = [col_lower['l'], col_lower['a'], col_lower['b']]\n",
    "        df['L_gt'] = df[lab_cols[0]]\n",
    "        df['a_gt'] = df[lab_cols[1]]\n",
    "        df['b_gt'] = df[lab_cols[2]]\n",
    "    else:\n",
    "        raise ValueError(f\"Ground-truth CSV doesn't contain recognizable color columns. Found: {list(df.columns)}\")\n",
    "\n",
    "    # Add full Munsell notation\n",
    "    df['munsell_notation'] = df.apply(get_full_munsell_notation, axis=1)\n",
    "    \n",
    "    # Add RGB values for display\n",
    "    lab_values = df[['L_gt', 'a_gt', 'b_gt']].values\n",
    "    rgb_values = lab2rgb(lab_values.reshape(-1, 1, 3)).reshape(-1, 3)\n",
    "    df[['R_display', 'G_display', 'B_display']] = rgb_values\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa69587",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extract_bone_pixels(img_path, bg_thresh=BACKGROUND_RGB_THRESH):\n",
    "    \"\"\"Enhanced bone pixel extraction with better handling.\"\"\"\n",
    "    img = io.imread(img_path)\n",
    "    if img.ndim == 2:\n",
    "        img = np.stack([img]*3, axis=-1)\n",
    "    \n",
    "    # Create mask for non-background pixels\n",
    "    mask = np.sum(img, axis=2) > bg_thresh * 3\n",
    "    bone_pixels_rgb = img[mask]\n",
    "    \n",
    "    if bone_pixels_rgb.size == 0:\n",
    "        return None, None\n",
    "    \n",
    "    # Convert to Lab color space using the same method as pipeline 1\n",
    "    # FIXED: Changed ast to astype\n",
    "    bone_pixels_rgb_float = bone_pixels_rgb.astype(np.float32) / 255.0\n",
    "    bone_pixels_rgb_float_reshaped = bone_pixels_rgb_float.reshape(-1, 1, 3)\n",
    "    \n",
    "    # Use cv2-style conversion for consistency\n",
    "    import cv2\n",
    "    bone_lab = cv2.cvtColor(bone_pixels_rgb_float_reshaped, cv2.COLOR_RGB2Lab)\n",
    "    bone_lab = bone_lab.reshape(-1, 3)\n",
    "    \n",
    "    return bone_lab, bone_pixels_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad1c67a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def quantize_bone_pixels_median_cut(bone_rgb, bone_lab, num_colors=QUANTIZATION_LEVELS):\n",
    "    \"\"\"\n",
    "    Apply median cut quantization to bone pixels.\n",
    "    \n",
    "    Args:\n",
    "        bone_rgb: RGB values of bone pixels (N, 3)\n",
    "        bone_lab: Lab values of bone pixels (N, 3)\n",
    "        num_colors: Number of colors to quantize to\n",
    "    \n",
    "    Returns:\n",
    "        centers: Quantized color centers in Lab space (num_colors, 3)\n",
    "        cluster_sizes: Number of pixels in each quantized color\n",
    "        labels: Cluster labels for each pixel\n",
    "    \"\"\"\n",
    "    # Apply median cut to RGB pixels\n",
    "    quantized_colors_rgb, labels = median_cut_quantization(bone_rgb, num_colors)\n",
    "    \n",
    "    # Convert quantized colors to Lab space\n",
    "    quantized_colors_rgb_float = quantized_colors_rgb.astype(np.float32) / 255.0\n",
    "    quantized_colors_rgb_float_reshaped = quantized_colors_rgb_float.reshape(-1, 1, 3)\n",
    "    \n",
    "    import cv2\n",
    "    quantized_colors_lab = cv2.cvtColor(quantized_colors_rgb_float_reshaped, cv2.COLOR_RGB2Lab)\n",
    "    quantized_colors_lab = quantized_colors_lab.reshape(-1, 3)\n",
    "    \n",
    "    # Calculate cluster sizes\n",
    "    cluster_sizes = np.bincount(labels, minlength=num_colors)\n",
    "    \n",
    "    return quantized_colors_lab, cluster_sizes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd980a4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def find_top_matches_enhanced(cluster_center, gt_df, top_n=TOP_N):\n",
    "    \"\"\"Enhanced matching using CIEDE2000 from colour library.\"\"\"\n",
    "    gt_lab_arr = gt_df[['L_gt','a_gt','b_gt']].values.astype(float)\n",
    "    \n",
    "    # Use colour library for CIEDE2000 (more accurate)\n",
    "    dE = colour.delta_E(cluster_center[np.newaxis, :], gt_lab_arr, method='CIE 2000')\n",
    "    \n",
    "    # Get indices of top N matches (lowest dE)\n",
    "    top_indices = np.argsort(dE)[:top_n]\n",
    "    \n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        row = gt_df.iloc[idx]\n",
    "        rgb_values = (row.get('R_display', 0), row.get('G_display', 0), row.get('B_display', 0))\n",
    "        \n",
    "        # Extract H, V, C values using various possible column names\n",
    "        h_val = None\n",
    "        v_val = None\n",
    "        c_val = None\n",
    "        \n",
    "        for h_col in ['h', 'H_GT', 'H', 'h_gt', 'Hue']:\n",
    "            if h_col in row and not pd.isna(row[h_col]):\n",
    "                h_val = row[h_col]\n",
    "                break\n",
    "                \n",
    "        for v_col in ['V', 'V_GT', 'v_gt', 'v', 'Value']:\n",
    "            if v_col in row and not pd.isna(row[v_col]):\n",
    "                v_val = row[v_col]\n",
    "                break\n",
    "                \n",
    "        for c_col in ['C', 'C_GT', 'c_gt', 'c', 'Chroma']:\n",
    "            if c_col in row and not pd.isna(row[c_col]):\n",
    "                c_val = row[c_col]\n",
    "                break\n",
    "        \n",
    "        results.append({\n",
    "            'dE': dE[idx],\n",
    "            'H': h_val,\n",
    "            'V': v_val,\n",
    "            'C': c_val,\n",
    "            'L_gt': row['L_gt'],\n",
    "            'a_gt': row['a_gt'],\n",
    "            'b_gt': row['b_gt'],\n",
    "            'munsell_notation': row.get('munsell_notation', 'Unknown'),\n",
    "            'rgb_values': rgb_values\n",
    "        })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da90c3e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_3d_scatter_best_cluster(bone_pixels_cluster, munsell_chip_lab, output_path):\n",
    "    \"\"\"Enhanced 3D scatter plot for the best cluster with perceptual coloring.\"\"\"\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Subsample for visualization if too many points\n",
    "    if len(bone_pixels_cluster) > 5000:\n",
    "        indices = np.random.choice(len(bone_pixels_cluster), 5000, replace=False)\n",
    "        plot_pixels = bone_pixels_cluster[indices]\n",
    "    else:\n",
    "        plot_pixels = bone_pixels_cluster\n",
    "    \n",
    "    # Calculate distance from each point to the Munsell chip\n",
    "    distances = np.sqrt(np.sum((plot_pixels - munsell_chip_lab)**2, axis=1))\n",
    "    \n",
    "    # Normalize distances for colormap\n",
    "    norm = plt.Normalize(vmin=distances.min(), vmax=distances.max())\n",
    "    cmap = plt.cm.plasma  # Perceptually uniform sequential colormap\n",
    "    \n",
    "    # Plot points with color based on distance\n",
    "    scatter = ax.scatter(plot_pixels[:, 0], plot_pixels[:, 1], plot_pixels[:, 2], \n",
    "                         c=distances, cmap=cmap, norm=norm, alpha=0.4, s=10)\n",
    "    \n",
    "    # Plot the Munsell chip\n",
    "    ax.scatter(munsell_chip_lab[0], munsell_chip_lab[1], munsell_chip_lab[2], \n",
    "               c='red', marker='o', s=300, label='Munsell Chip', edgecolors='black')\n",
    "    \n",
    "    ax.set_xlabel('L*')\n",
    "    ax.set_ylabel('a*')\n",
    "    ax.set_zlabel('b*')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(scatter, ax=ax, shrink=0.5, aspect=20)\n",
    "    cbar.set_label('Distance from Munsell Chip (Î”E)')\n",
    "    \n",
    "    # Title removed as requested\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b768f8f1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_enhanced_visualization(img_path, cluster_centers, cluster_sizes, top_matches_list, \n",
    "                                optimal_k, bone_lab, cluster_labels, gt_df, output_dir, img_name):\n",
    "    \"\"\"Enhanced visualization for median cut quantization.\"\"\"\n",
    "    \n",
    "    # 1. Main comparison plot (showing top 5 clusters)\n",
    "    top_indices = np.argsort([matches[0]['dE'] for matches in top_matches_list])[:min(5, optimal_k)]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(top_indices) + 1, figsize=(22, 5))\n",
    "    \n",
    "    # Original image\n",
    "    img = io.imread(img_path)\n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_title(f\"({optimal_k} colors via Median Cut)\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Top matches visualization\n",
    "    for i, cluster_idx in enumerate(top_indices):\n",
    "        match = top_matches_list[cluster_idx][0]  # Best match for this cluster\n",
    "        \n",
    "        # Get RGB color for display\n",
    "        rgb_color = match['rgb_values']\n",
    "        \n",
    "        axes[i + 1].imshow([[rgb_color]])\n",
    "        \n",
    "        munsell_notation = match['munsell_notation']\n",
    "        rgb_text = f\"RGB: ({rgb_color[0]:.2f}, {rgb_color[1]:.2f}, {rgb_color[2]:.2f})\"\n",
    "        \n",
    "        axes[i + 1].set_title(f\"Color {cluster_idx + 1} Match\\n{munsell_notation}\\n{rgb_text}\\nÎ”E2000: {match['dE']:.2f}\\nSize: {cluster_sizes[cluster_idx]} px\")\n",
    "        axes[i + 1].axis('off')\n",
    "        axes[i + 1].add_patch(Rectangle((0, 0), 1, 1, facecolor=rgb_color, edgecolor='black', linewidth=2))\n",
    "\n",
    "    # Main title removed as requested\n",
    "    main_plot_path = os.path.join(output_dir, f\"{img_name}_median_cut_analysis.png\")\n",
    "    plt.savefig(main_plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. 3D scatter plot for best cluster\n",
    "    best_cluster_idx = np.argmin([matches[0]['dE'] for matches in top_matches_list])\n",
    "    best_cluster_pixels = bone_lab[cluster_labels == best_cluster_idx]\n",
    "    best_match = top_matches_list[best_cluster_idx][0]\n",
    "    best_munsell_lab = np.array([best_match['L_gt'], best_match['a_gt'], best_match['b_gt']])\n",
    "    \n",
    "    scatter_path = os.path.join(output_dir, f\"{img_name}_3d_scatter.png\")\n",
    "    plot_3d_scatter_best_cluster(best_cluster_pixels, best_munsell_lab, scatter_path)\n",
    "    \n",
    "    # 3. Detailed analysis plot\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0, 0].imshow(img)\n",
    "    axes[0, 0].set_title('Original Bone Image')  # Simple title\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Cluster centers in Lab space\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, optimal_k))\n",
    "    for i, (center, size) in enumerate(zip(cluster_centers, cluster_sizes)):\n",
    "        rgb_color = lab2rgb(center.reshape(1, 1, 3)).reshape(3)\n",
    "        rgb_color = np.clip(rgb_color, 0, 1)\n",
    "        axes[0, 1].scatter(center[1], center[2], color=rgb_color, s=size/10, \n",
    "                          alpha=0.7, edgecolor='black', label=f'Color {i+1}')\n",
    "    \n",
    "    axes[0, 1].set_xlabel('a*')\n",
    "    axes[0, 1].set_ylabel('b*')\n",
    "    axes[0, 1].set_title('Color Centers in Lab Space (size = pixel count/10)')\n",
    "    axes[0, 1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Î”E distribution by cluster\n",
    "    for cluster_idx, (top_matches, color) in enumerate(zip(top_matches_list, colors)):\n",
    "        dE_values = [match['dE'] for match in top_matches]\n",
    "        axes[1, 0].plot(range(1, min(len(dE_values), TOP_N)+1), dE_values[:TOP_N], \n",
    "                       'o-', color=color, label=f'Color {cluster_idx+1}')\n",
    "    \n",
    "    axes[1, 0].set_xlabel('Match Rank')\n",
    "    axes[1, 0].set_ylabel('Î”E2000')\n",
    "    axes[1, 0].set_title('Î”E2000 for Top Matches by Color')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Color swatches for best cluster (top 5 matches)\n",
    "    best_matches = top_matches_list[best_cluster_idx][:5]\n",
    "    for i, match in enumerate(best_matches):\n",
    "        rgb_color = match['rgb_values']\n",
    "        axes[1, 1].add_patch(plt.Rectangle((i, 0), 0.8, 0.8, color=rgb_color, edgecolor='black'))\n",
    "        axes[1, 1].text(i + 0.4, -0.15, f\"Î”E={match['dE']:.2f}\", ha='center', fontsize=10)\n",
    "        munsell_text = match['munsell_notation']\n",
    "        axes[1, 1].text(i + 0.4, 0.9, munsell_text, ha='center', fontsize=9, rotation=45)\n",
    "    \n",
    "    axes[1, 1].set_xlim(-0.5, 5.5)\n",
    "    axes[1, 1].set_ylim(-0.5, 1.2)\n",
    "    axes[1, 1].set_title(f'Top 5 Matches for Best Color ({best_cluster_idx + 1})')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    detailed_path = os.path.join(output_dir, f\"{img_name}_detailed_analysis.png\")\n",
    "    plt.savefig(detailed_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1d8741",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def process_single_image(img_path, gt_df, output_dir):\n",
    "    \"\"\"Process a single bone image with median cut quantization.\"\"\"\n",
    "    img_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    \n",
    "    try:\n",
    "        # Extract bone pixels\n",
    "        bone_lab, bone_rgb = extract_bone_pixels(img_path)\n",
    "        if bone_lab is None:\n",
    "            print(f\"Skipping {img_path} - no bone pixels detected\")\n",
    "            return []\n",
    "        \n",
    "        print(f\"  Found {len(bone_lab)} bone pixels\")\n",
    "        \n",
    "        # Apply median cut quantization\n",
    "        cluster_centers, cluster_sizes, cluster_labels = quantize_bone_pixels_median_cut(\n",
    "            bone_rgb, bone_lab, QUANTIZATION_LEVELS)\n",
    "        \n",
    "        print(f\"  Quantized into {QUANTIZATION_LEVELS} colors\")\n",
    "        \n",
    "        # Find top matches for each color\n",
    "        top_matches_list = []\n",
    "        cluster_results = []\n",
    "        \n",
    "        for i, center in enumerate(cluster_centers):\n",
    "            top_matches = find_top_matches_enhanced(center, gt_df, top_n=TOP_N)\n",
    "            top_matches_list.append(top_matches)\n",
    "            \n",
    "            # Store results\n",
    "            for j, match in enumerate(top_matches):\n",
    "                cluster_results.append({\n",
    "                    \"image_path\": img_path,\n",
    "                    \"image_name\": img_name,\n",
    "                    \"color_id\": i+1,\n",
    "                    \"color_size\": cluster_sizes[i],\n",
    "                    \"color_size_pct\": cluster_sizes[i] / len(bone_lab) * 100,\n",
    "                    \"quantization_levels\": QUANTIZATION_LEVELS,\n",
    "                    \"color_L\": center[0],\n",
    "                    \"color_a\": center[1],\n",
    "                    \"color_b\": center[2],\n",
    "                    \"match_rank\": j+1,\n",
    "                    \"dE2000\": match['dE'],\n",
    "                    \"gt_H\": match['H'],\n",
    "                    \"gt_V\": match['V'],\n",
    "                    \"gt_C\": match['C'],\n",
    "                    \"gt_L\": match['L_gt'],\n",
    "                    \"gt_a\": match['a_gt'],\n",
    "                    \"gt_b\": match['b_gt'],\n",
    "                    \"munsell_notation\": match['munsell_notation'],\n",
    "                    \"rgb_R\": match['rgb_values'][0],\n",
    "                    \"rgb_G\": match['rgb_values'][1],\n",
    "                    \"rgb_B\": match['rgb_values'][2]\n",
    "                })\n",
    "        \n",
    "        # Calculate statistics for this image\n",
    "        if cluster_results:\n",
    "            dE_values = [result['dE2000'] for result in cluster_results if result['match_rank'] == 1]\n",
    "            if dE_values:\n",
    "                stats = {\n",
    "                    \"image_path\": img_path,\n",
    "                    \"image_name\": img_name,\n",
    "                    \"min_dE\": np.min(dE_values),\n",
    "                    \"max_dE\": np.max(dE_values),\n",
    "                    \"mean_dE\": np.mean(dE_values),\n",
    "                    \"std_dE\": np.std(dE_values),\n",
    "                    \"median_dE\": np.median(dE_values),\n",
    "                    \"num_colors\": QUANTIZATION_LEVELS\n",
    "                }\n",
    "                # Add these stats to your results or save separately\n",
    "        \n",
    "        # Create enhanced visualizations\n",
    "        create_enhanced_visualization(img_path, cluster_centers, cluster_sizes, top_matches_list,\n",
    "                                    QUANTIZATION_LEVELS, bone_lab, cluster_labels, gt_df, output_dir, img_name)\n",
    "        \n",
    "        print(f\"  Generated visualizations and analysis\")\n",
    "        return cluster_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_path}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1998b533",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def calculate_statistics(all_results):\n",
    "    \"\"\"Calculate comprehensive statistics from all results.\"\"\"\n",
    "    if not all_results:\n",
    "        return None\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    res_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    # Calculate per-image statistics\n",
    "    image_stats = []\n",
    "    for img_name in res_df['image_name'].unique():\n",
    "        img_data = res_df[res_df['image_name'] == img_name]\n",
    "        best_matches = img_data[img_data['match_rank'] == 1]\n",
    "        \n",
    "        if len(best_matches) > 0:\n",
    "            image_stats.append({\n",
    "                \"image_name\": img_name,\n",
    "                \"min_dE\": best_matches['dE2000'].min(),\n",
    "                \"max_dE\": best_matches['dE2000'].max(),\n",
    "                \"mean_dE\": best_matches['dE2000'].mean(),\n",
    "                \"std_dE\": best_matches['dE2000'].std(),\n",
    "                \"median_dE\": best_matches['dE2000'].median(),\n",
    "                \"num_colors\": QUANTIZATION_LEVELS,\n",
    "                \"total_pixels\": best_matches['color_size'].sum()\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(image_stats), res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d0007f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_statistics_visualization(stats_df, output_dir):\n",
    "    \"\"\"Create visualization of the statistics.\"\"\"\n",
    "    if stats_df is None or len(stats_df) == 0:\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Î”E distribution\n",
    "    axes[0, 0].hist(stats_df['mean_dE'], bins=20, alpha=0.7, edgecolor='black')\n",
    "    axes[0, 0].set_xlabel('Mean Î”E2000 per Image')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].set_title('Distribution of Mean Î”E2000 Values')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Min vs Max Î”E\n",
    "    axes[0, 1].scatter(stats_df['min_dE'], stats_df['max_dE'], alpha=0.6)\n",
    "    axes[0, 1].set_xlabel('Minimum Î”E2000')\n",
    "    axes[0, 1].set_ylabel('Maximum Î”E2000')\n",
    "    axes[0, 1].set_title('Minimum vs Maximum Î”E2000 per Image')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Standard Deviation\n",
    "    axes[1, 0].hist(stats_df['std_dE'], bins=20, alpha=0.7, edgecolor='black')\n",
    "    axes[1, 0].set_xlabel('Standard Deviation of Î”E2000')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].set_title('Distribution of Î”E2000 Standard Deviations')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Pixel count vs Î”E\n",
    "    axes[1, 1].scatter(stats_df['total_pixels'], stats_df['mean_dE'], alpha=0.6)\n",
    "    axes[1, 1].set_xlabel('Total Pixels in Image')\n",
    "    axes[1, 1].set_ylabel('Mean Î”E2000')\n",
    "    axes[1, 1].set_title('Image Size vs Color Accuracy')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    stats_plot_path = os.path.join(output_dir, \"median_cut_statistics_visualization.png\")\n",
    "    plt.savefig(stats_plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Statistics visualization: {stats_plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f75f3a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ========== MAIN EXECUTION ==========\n",
    "def main():\n",
    "    print(\"Bone Color Analysis with Median Cut Quantization\")\n",
    "    print(\"================================================\")\n",
    "    \n",
    "    # Load ground truth\n",
    "    print(\"Loading Munsell ground truth...\")\n",
    "    try:\n",
    "        gt_df = load_munsell_groundtruth(MUNSELL_CSV)\n",
    "        print(f\"Loaded {len(gt_df)} Munsell color references\")\n",
    "        \n",
    "        # Print column names to help debug\n",
    "        print(f\"Columns in ground truth: {list(gt_df.columns)}\")\n",
    "        \n",
    "        # Check if Munsell notation is working\n",
    "        print(f\"Sample Munsell notations: {gt_df['munsell_notation'].head()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading ground truth: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Get image files\n",
    "    image_paths = []\n",
    "    for fname in os.listdir(BONE_IMAGES_DIR):\n",
    "        if fname.lower().endswith(('.png','.jpg','.jpeg','.tiff','.bmp')):\n",
    "            image_paths.append(os.path.join(BONE_IMAGES_DIR, fname))\n",
    "    \n",
    "    if not image_paths:\n",
    "        print(f\"No images found in {BONE_IMAGES_DIR}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(image_paths)} bone images to process\")\n",
    "    \n",
    "    # Process all images\n",
    "    all_results = []\n",
    "    for img_path in tqdm(image_paths, desc=\"Processing images\"):\n",
    "        print(f\"\\nProcessing: {os.path.basename(img_path)}\")\n",
    "        results = process_single_image(img_path, gt_df, OUTPUT_DIR)\n",
    "        all_results.extend(results)\n",
    "    \n",
    "    # Save comprehensive results\n",
    "    if all_results:\n",
    "        print(f\"\\nSaving results for {len(all_results)} color matches...\")\n",
    "        \n",
    "        # Calculate statistics\n",
    "        stats_df, res_df = calculate_statistics(all_results)\n",
    "        \n",
    "        # Save detailed results\n",
    "        all_csv = os.path.join(OUTPUT_DIR, \"median_cut_bone_deltae_results.csv\")\n",
    "        res_df.to_csv(all_csv, index=False)\n",
    "        print(f\"Detailed results: {all_csv}\")\n",
    "        \n",
    "        # Save statistics\n",
    "        if stats_df is not None and len(stats_df) > 0:\n",
    "            stats_csv = os.path.join(OUTPUT_DIR, \"median_cut_statistics_summary.csv\")\n",
    "            stats_df.to_csv(stats_csv, index=False)\n",
    "            print(f\"Statistics summary: {stats_csv}\")\n",
    "            \n",
    "            # Create statistics visualization\n",
    "            create_statistics_visualization(stats_df, OUTPUT_DIR)\n",
    "            \n",
    "            # Print comprehensive summary\n",
    "            print(f\"\\n=== ANALYSIS COMPLETE ===\")\n",
    "            print(f\"Processed: {len(image_paths)} images\")\n",
    "            print(f\"Generated: {len(all_results)} color-match pairs\")\n",
    "            print(f\"Best Î”E2000: {stats_df['min_dE'].min():.2f}\")\n",
    "            print(f\"Worst Î”E2000: {stats_df['max_dE'].max():.2f}\")\n",
    "            print(f\"Mean Î”E2000: {stats_df['mean_dE'].mean():.2f}\")\n",
    "            print(f\"Median Î”E2000: {stats_df['median_dE'].median():.2f}\")\n",
    "            print(f\"Average Standard Deviation: {stats_df['std_dE'].mean():.2f}\")\n",
    "            print(f\"Results saved to: {OUTPUT_DIR}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"No results generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a385ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

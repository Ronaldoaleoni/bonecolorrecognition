{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fb2686-7947-40be-9ab0-e0d0592f3e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import detectron2\n",
    "import cv2\n",
    "import numpy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.structures import Boxes, BoxMode, Instances\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, DatasetMapper\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4aea7164-e711-40e9-89e0-ce2a87603f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Registering test dataset\n",
    "dataset_name_test = \"test_set\" \n",
    "annotation_file_path_test = \"<your-path-here>/assets/annotations.json\"  \n",
    "image_directory_path_test = \"<your-path-here>/assets/images\" \n",
    "\n",
    "register_coco_instances(dataset_name_test, {}, annotation_file_path_test, image_directory_path_test)\n",
    "\n",
    "test_metadata = MetadataCatalog.get(\"test_set\")\n",
    "test_dataset_dicts = DatasetCatalog.get(\"test_set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d914624d-e3c0-4373-aad7-9b69d101f8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new cfg for testing\n",
    "test_cfg = get_cfg()\n",
    "\n",
    "# Load the config from the trained model\n",
    "test_cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")) \n",
    "\n",
    "# Set the path to the trained weight\n",
    "test_cfg.MODEL.WEIGHTS = \"<your-path-here>/detectron2/model_final.pth\"\n",
    "\n",
    "# Adjust testing-specific parameters\n",
    "test_cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Confidence threshold for predictions\n",
    "test_cfg.DATASETS.TEST = (\"test_set\",)  # Make sure this matches your registered test dataset\n",
    "test_cfg.DATALOADER.NUM_WORKERS = 2 # Set this equal to the number of CPU cores on your machine, decrease or increase based on the performance and system resource usage\n",
    "test_cfg.INPUT.MIN_SIZE_TEST = 512 # Min image size\n",
    "test_cfg.INPUT.MAX_SIZE_TEST = 512 # Max image size\n",
    "test_cfg.MODEL.DEVICE = \"cuda\"  # Use \"cpu\" if you're testing on CPU\n",
    "test_cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1 #Number of classes the model want to detect\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff47d85b-b1a3-431a-9cb2-b7dd6aaef8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the predictor with the new test configuration\n",
    "predictor = DefaultPredictor(test_cfg)\n",
    "\n",
    "# Set test metadata\n",
    "test_metadata = MetadataCatalog.get(\"test_set\")\n",
    "\n",
    "# Create test data loader with resizing\n",
    "test_loader = build_detection_test_loader(\n",
    "    test_cfg, \n",
    "    \"test_set\", \n",
    "    mapper=DatasetMapper(test_cfg, is_train=False)\n",
    ")\n",
    "\n",
    "# Output directory for visualizations\n",
    "output_visualization_dir = \"<your-path-here>/test_set_predictions\"\n",
    "os.makedirs(output_visualization_dir, exist_ok=True)\n",
    "\n",
    "# Iterate through test set\n",
    "with torch.no_grad():  # Disable gradients to save GPU memory\n",
    "    for batch in test_loader:\n",
    "        for data in batch:\n",
    "            img = cv2.imread(data[\"file_name\"])\n",
    "            outputs = predictor(img)\n",
    "\n",
    "            # Visualize predictions\n",
    "            v = Visualizer(\n",
    "                img[:, :, ::-1], \n",
    "                metadata=test_metadata,\n",
    "                instance_mode=ColorMode.SEGMENTATION\n",
    "            )\n",
    "            out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "            # Save visualized image\n",
    "            output_filepath = os.path.join(output_visualization_dir, os.path.basename(data[\"file_name\"]))\n",
    "            cv2.imwrite(output_filepath, out.get_image()[:, :, ::-1])\n",
    "\n",
    "print(f\"Visualizations saved to: {output_visualization_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe05277d-f88c-45a6-98da-1942e2060953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config and model\n",
    "predictor = DefaultPredictor(test_cfg)\n",
    "\n",
    "# Paths\n",
    "input_dir = \"<your-path-here>/assets/images\"\n",
    "output_dir = \"<your-path-here>\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "output_size = 1024\n",
    "padding_percentage = 0.1\n",
    "\n",
    "\n",
    "# Processing loop\n",
    "bone_counter = 1  # Initialize global counter for naming bones\n",
    "\n",
    "for idx, image_file in enumerate(sorted(os.listdir(input_dir))):\n",
    "    if not image_file.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".tif\")):\n",
    "        continue\n",
    "\n",
    "    input_path = os.path.join(input_dir, image_file)\n",
    "    img = cv2.imread(input_path)\n",
    "    if img is None:\n",
    "        print(f\"⚠️ Could not read {image_file}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Run Mask R-CNN\n",
    "    outputs = predictor(img)\n",
    "    if len(outputs[\"instances\"]) == 0:\n",
    "        print(f\"⚠️ No bone detected in {image_file}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    masks = outputs[\"instances\"].pred_masks.cpu().numpy().astype(np.uint8)\n",
    "\n",
    "    # Process each bone separately\n",
    "    for b_idx, mask in enumerate(masks):\n",
    "        ys, xs = np.where(mask > 0)\n",
    "        if len(xs) == 0 or len(ys) == 0:\n",
    "            continue  # skip empty mask\n",
    "\n",
    "        # Bounding box\n",
    "        min_x, max_x = xs.min(), xs.max()\n",
    "        min_y, max_y = ys.min(), ys.max()\n",
    "\n",
    "        # Add padding\n",
    "        pad_x = int((max_x - min_x) * padding_percentage)\n",
    "        pad_y = int((max_y - min_y) * padding_percentage)\n",
    "        min_x = max(0, min_x - pad_x)\n",
    "        min_y = max(0, min_y - pad_y)\n",
    "        max_x = min(img.shape[1], max_x + pad_x)\n",
    "        max_y = min(img.shape[0], max_y + pad_y)\n",
    "\n",
    "        # Crop bone region\n",
    "        cropped_img = img[min_y:max_y, min_x:max_x]\n",
    "        cropped_mask = mask[min_y:max_y, min_x:max_x]\n",
    "\n",
    "        # Apply mask\n",
    "        bone_only = np.zeros_like(cropped_img)\n",
    "        bone_only[cropped_mask > 0] = cropped_img[cropped_mask > 0]\n",
    "\n",
    "        # Prepare final black 1024×1024 canvas\n",
    "        black_canvas = np.zeros((output_size, output_size, 3), dtype=np.uint8)\n",
    "        ch, cw = bone_only.shape[:2]\n",
    "\n",
    "        # Resize if needed\n",
    "        if ch > output_size or cw > output_size:\n",
    "            scale = min(output_size / ch, output_size / cw)\n",
    "            bone_only = cv2.resize(bone_only, (int(cw * scale), int(ch * scale)), interpolation=cv2.INTER_AREA)\n",
    "            ch, cw = bone_only.shape[:2]\n",
    "\n",
    "        # Center placement\n",
    "        offset_y = (output_size - ch) // 2\n",
    "        offset_x = (output_size - cw) // 2\n",
    "        black_canvas[offset_y:offset_y+ch, offset_x:offset_x+cw] = bone_only\n",
    "\n",
    "        # Save each bone separately\n",
    "        output_name = f\"{bone_counter:04d}.png\" \n",
    "        cv2.imwrite(os.path.join(output_dir, output_name), black_canvas)\n",
    "        print(f\"✅ Saved {output_name}\")\n",
    "        bone_counter += 1  # Increment counter\n",
    "\n",
    "print(\"All images processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf52157-b5ce-4b0d-8b9c-4a04acf4135f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
